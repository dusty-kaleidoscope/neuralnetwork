{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab92d959",
   "metadata": {},
   "source": [
    "# Gradient Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f31177",
   "metadata": {},
   "source": [
    "We will check the gradient computation using the circle data. We will check it for both the `mse` loss and `cce` loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3c676",
   "metadata": {},
   "source": [
    "## Todo\n",
    "\n",
    "1. Address issues w/ derivative at boundary of ReLu function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2016923",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c177b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import node\n",
    "import layer\n",
    "import importlib\n",
    "import neuralnetwork\n",
    "\n",
    "from node import mse, mse_grad, bce, bce_grad, cce, cce_grad\n",
    "\n",
    "from typing import List\n",
    "from operator import add, mul, matmul\n",
    "\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187167ac",
   "metadata": {},
   "source": [
    "## Set Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d68a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7192026",
   "metadata": {},
   "source": [
    "## For BCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb7d3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the cpu!\n",
      "Starting epoch 0\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Training took 2.3763794580008835 seconds on the cpu\n"
     ]
    }
   ],
   "source": [
    "# limit set at 10^-5\n",
    "# will raise warning if relative error exceeds limit\n",
    "# warning doesn't necessarily mean error\n",
    "\n",
    "training_points = 10000\n",
    "\n",
    "run_circle_check = True\n",
    "\n",
    "use_gpu = False\n",
    "\n",
    "if use_gpu:\n",
    "    if torch.cuda.is_available():\n",
    "        my_device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA gpu!\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        my_device = torch.device(\"mps\")\n",
    "        print(\"Using MPS gpu!\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    print(\"Using the cpu!\")\n",
    "\n",
    "if run_circle_check:\n",
    "    \n",
    "    X_train = np.random.rand(training_points, 2) * 4 - 2\n",
    "    #X_train = np.array([[1, 10]])\n",
    "    y_train_true = np.power(X_train, 2).sum(axis = 1)  > 1\n",
    "    \n",
    "    X_train_formatted = torch.Tensor(X_train.T).to(my_device)\n",
    "    y_train_formatted = torch.Tensor(y_train_true.T).to(my_device).unsqueeze(dim = 0)\n",
    " \n",
    "    model = neuralnetwork.NeuralNetwork([(2, \"id\"), \n",
    "                                         (10, \"tanh\"), \n",
    "                                         (10, \"tanh\"), \n",
    "                                         (1, \"id\")])\n",
    "    model.randomize_params()\n",
    "    \n",
    "    model.to_device(my_device)\n",
    "    \n",
    "    model_delta = neuralnetwork.NeuralNetwork([(2, \"id\"), \n",
    "                                         (10, \"tanh\"), \n",
    "                                         (10, \"tanh\"), \n",
    "                                         (1, \"id\")])\n",
    "    \n",
    "    epochs = 3\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # over each epoch, we randomly split the data into batches then train\n",
    "        \n",
    "        print(f\"Starting epoch {i}\")\n",
    "        batch_size = int(training_points / 10)\n",
    "        \n",
    "        shuffled = torch.randperm(training_points)\n",
    "        \n",
    "        X_shuffled = X_train_formatted[ : , shuffled]\n",
    "        y_shuffled = y_train_formatted[ : , shuffled]\n",
    "        \n",
    "        \n",
    "        X_partitions = torch.split(X_shuffled, batch_size, dim = 1)\n",
    "        y_partitions = torch.split(y_shuffled, batch_size, dim = 1)\n",
    "        \n",
    "        for X_batch, y_batch in zip(X_partitions, y_partitions):\n",
    "        \n",
    "            model.copy(model_delta)\n",
    "            model.compute_grads(X_batch, y_batch.float(), error = \"bce\")\n",
    "            orig_loss = bce(y_batch.float(), model_delta.predict(X_batch))\n",
    "\n",
    "            h = 0.00001\n",
    "            limit = 0.0001\n",
    "            for k, param in enumerate(model.params):\n",
    "                \n",
    "                    delta = torch.zeros(param.weight.forward_value.shape)\n",
    "                    m, n = delta.shape\n",
    "                    for i in range(m):\n",
    "                        for j in range(n):\n",
    "                            \n",
    "                            delta[i][j] = h\n",
    "                            \n",
    "                            model_delta.add_delta(k, \"weight\", delta)\n",
    "                            plus_loss = bce(y_batch.float(), model_delta.predict(X_batch))\n",
    "                            \n",
    "                            model_delta.add_delta(k, \"weight\", -delta,)\n",
    "                            model_delta.add_delta(k, \"weight\", -delta,)\n",
    "                            minus_loss = bce(y_batch.float(), model_delta.predict(X_batch))\n",
    "                            \n",
    "                            estimated_grad = (plus_loss - minus_loss) / (2 * h)\n",
    "                            true_grad = param.weight.backward_value[i][j]\n",
    "                            diff = estimated_grad - true_grad\n",
    "                            relative_error = torch.norm(diff) / torch.norm(estimated_grad + true_grad) \n",
    "                            \n",
    "                            if (relative_error > limit):\n",
    "                                print(f\"Concerning relative error detected for weight in layer {k} in entry {i, j}! The error was {relative_error}\")\n",
    "                        \n",
    "                            model_delta.add_delta(k, \"weight\", delta)\n",
    "                            \n",
    "                            delta[i][j] = 0\n",
    "                            \n",
    "                    delta = torch.zeros(param.bias.forward_value.shape)\n",
    "                    m, n = delta.shape\n",
    "                    for i in range(m):\n",
    "                        for j in range(n):\n",
    "                            \n",
    "                            delta[i][j] = h\n",
    "                            \n",
    "                            model_delta.add_delta(k, \"bias\", delta)\n",
    "        \n",
    "                            plus_loss = bce(y_batch.float(), model_delta.predict(X_batch))\n",
    "                            \n",
    "                            model_delta.add_delta(k, \"bias\", -delta,)\n",
    "                            model_delta.add_delta(k, \"bias\", -delta,)\n",
    "                            minus_loss = bce(y_batch.float(), model_delta.predict(X_batch))\n",
    "                            \n",
    "                            estimated_grad = (plus_loss - minus_loss) / (2 * h)\n",
    "                            true_grad = param.bias.backward_value[i][j]\n",
    "                            diff = estimated_grad - true_grad\n",
    "                            relative_error = torch.norm(diff) / torch.norm(estimated_grad + true_grad) \n",
    "                            \n",
    "                            if (relative_error > limit):\n",
    "                                print(f\"Concerning relative error detected for bias in layer {k} in entry {i, j}! The error was {relative_error}\")\n",
    "                        \n",
    "                            \n",
    "                            model_delta.add_delta(k, \"bias\", delta)\n",
    "                            \n",
    "                            delta[i][j] = 0\n",
    "                            \n",
    "            model.update(learning_rate = 0.1)\n",
    "        \n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Training took {end_time - start_time} seconds on the {my_device}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcbdee",
   "metadata": {},
   "source": [
    "## For MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1108a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the cpu!\n",
      "Starting epoch 0\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Training took 1.8731855420010106 seconds on the cpu\n"
     ]
    }
   ],
   "source": [
    "# limit set at 10^-5\n",
    "# will raise warning if relative error exceeds limit\n",
    "# warning doesn't necessarily mean error\n",
    "\n",
    "training_points = 10000\n",
    "\n",
    "run_circle_check = True\n",
    "\n",
    "use_gpu = False\n",
    "\n",
    "if use_gpu:\n",
    "    if torch.cuda.is_available():\n",
    "        my_device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA gpu!\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        my_device = torch.device(\"mps\")\n",
    "        print(\"Using MPS gpu!\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    print(\"Using the cpu!\")\n",
    "\n",
    "if run_circle_check:\n",
    "    \n",
    "    X_train = np.random.rand(training_points, 2) * 4 - 2\n",
    "    #X_train = np.array([[1, 10]])\n",
    "    y_train_true = np.power(X_train, 2).sum(axis = 1)  > 1\n",
    "    \n",
    "    X_train_formatted = torch.Tensor(X_train.T).to(my_device)\n",
    "    y_train_formatted = torch.Tensor(y_train_true.T).to(my_device).unsqueeze(dim = 0)\n",
    " \n",
    "    model = neuralnetwork.NeuralNetwork([(2, \"id\"), \n",
    "                                         (10, \"tanh\"), \n",
    "                                         (10, \"tanh\"), \n",
    "                                         (1, \"id\")])\n",
    "    model.randomize_params()\n",
    "    \n",
    "    model.to_device(my_device)\n",
    "    \n",
    "    model_delta = neuralnetwork.NeuralNetwork([(2, \"id\"), \n",
    "                                         (10, \"tanh\"), \n",
    "                                         (10, \"tanh\"), \n",
    "                                         (1, \"id\")])\n",
    "    \n",
    "    epochs = 3\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # over each epoch, we randomly split the data into batches then train\n",
    "        \n",
    "        print(f\"Starting epoch {i}\")\n",
    "        batch_size = int(training_points / 10)\n",
    "        \n",
    "        shuffled = torch.randperm(training_points)\n",
    "        \n",
    "        X_shuffled = X_train_formatted[ : , shuffled]\n",
    "        y_shuffled = y_train_formatted[ : , shuffled]\n",
    "        \n",
    "        \n",
    "        X_partitions = torch.split(X_shuffled, batch_size, dim = 1)\n",
    "        y_partitions = torch.split(y_shuffled, batch_size, dim = 1)\n",
    "        \n",
    "        for X_batch, y_batch in zip(X_partitions, y_partitions):\n",
    "        \n",
    "            model.copy(model_delta)\n",
    "            model.compute_grads(X_batch, y_batch.float(), error = \"mse\")\n",
    "            orig_loss = mse(y_batch.float(), model_delta.predict(X_batch))\n",
    "\n",
    "            h = 0.00001\n",
    "            limit = 0.0001\n",
    "            for k, param in enumerate(model.params):\n",
    "                \n",
    "                    delta = torch.zeros(param.weight.forward_value.shape)\n",
    "                    m, n = delta.shape\n",
    "                    for i in range(m):\n",
    "                        for j in range(n):\n",
    "                            \n",
    "                            delta[i][j] = h\n",
    "                            \n",
    "                            model_delta.add_delta(k, \"weight\", delta)\n",
    "                            plus_loss = mse(y_batch.float(), model_delta.predict(X_batch))\n",
    "                            \n",
    "                            model_delta.add_delta(k, \"weight\", -delta,)\n",
    "                            model_delta.add_delta(k, \"weight\", -delta,)\n",
    "                            minus_loss = mse(y_batch.float(), model_delta.predict(X_batch))\n",
    "                            \n",
    "                            estimated_grad = (plus_loss - minus_loss) / (2 * h)\n",
    "                            true_grad = param.weight.backward_value[i][j]\n",
    "                            diff = estimated_grad - true_grad\n",
    "                            relative_error = torch.norm(diff) / torch.norm(estimated_grad + true_grad) \n",
    "                            \n",
    "                            if (relative_error > limit):\n",
    "                                print(f\"Concerning relative error detected for weight in layer {k} in entry {i, j}! The error was {relative_error}\")\n",
    "                        \n",
    "                            model_delta.add_delta(k, \"weight\", delta)\n",
    "                            \n",
    "                            delta[i][j] = 0\n",
    "                            \n",
    "                    delta = torch.zeros(param.bias.forward_value.shape)\n",
    "                    m, n = delta.shape\n",
    "                    for i in range(m):\n",
    "                        for j in range(n):\n",
    "                            \n",
    "                            delta[i][j] = h\n",
    "                            \n",
    "                            model_delta.add_delta(k, \"bias\", delta)\n",
    "        \n",
    "                            plus_loss = mse(y_batch.float(), model_delta.predict(X_batch))\n",
    "                            \n",
    "                            model_delta.add_delta(k, \"bias\", -delta,)\n",
    "                            model_delta.add_delta(k, \"bias\", -delta,)\n",
    "                            minus_loss = mse(y_batch.float(), model_delta.predict(X_batch))\n",
    "                            \n",
    "                            estimated_grad = (plus_loss - minus_loss) / (2 * h)\n",
    "                            true_grad = param.bias.backward_value[i][j]\n",
    "                            diff = estimated_grad - true_grad\n",
    "                            relative_error = torch.norm(diff) / torch.norm(estimated_grad + true_grad) \n",
    "                            \n",
    "                            if (relative_error > limit):\n",
    "                                print(f\"Concerning relative error detected for bias in layer {k} in entry {i, j}! The error was {relative_error}\")\n",
    "                        \n",
    "                            \n",
    "                            model_delta.add_delta(k, \"bias\", delta)\n",
    "                            \n",
    "                            delta[i][j] = 0\n",
    "                            \n",
    "            model.update(learning_rate = 0.1)\n",
    "        \n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Training took {end_time - start_time} seconds on the {my_device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python w/ MPS",
   "language": "python",
   "name": "my_mps_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
